{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f26fa7-bc58-4fa9-93dd-5fc05985a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List  \n",
    "import warnings\n",
    "\n",
    "import openai\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re \n",
    "import signal \n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8957fe0-7266-485d-9862-e5f6a2471850",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### converting data to text for \"no_cov_no_bmi\" ###############\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Health_data_text_converter: \n",
    "    def __init__(self): \n",
    "        self.mappings = {\n",
    "            'gender': {1: \"male\", 2: \"female\"}, \n",
    "            'race': {1: \"Mexican American\", \n",
    "                     2: \"Other Hispanic\", \n",
    "                     3: \"Non-Hispanic White\", \n",
    "                     4: \"Non-Hispanic Black\", \n",
    "                     5: \"Other\"},\n",
    "            'education': {1: \"less than 9th grade\", \n",
    "                          2: \"9-11th grade (includes 12th grade and no diploma)\", \n",
    "                          3: \"high school graduate/GED or equivalent\", \n",
    "                          4: \"some college or associates (AA) degree\", \n",
    "                          5: \"college graduate or higher\"},\n",
    "            'marital_status': {1: \"married\", \n",
    "                        2: \"widowed\", \n",
    "                        3: \"divorced\", \n",
    "                        4: \"separated\", \n",
    "                        5: \"never married\", \n",
    "                        6: \"living with partner\"},\n",
    "            'physical_activity': {0: \"sedentary\", \n",
    "                                  1: \"light activity\",\n",
    "                                  2: \"lifestyle activity\", \n",
    "                                  3: \"moderate activity\", \n",
    "                                  4: \"vigorous activity\"}\n",
    "        }\n",
    "\n",
    "    def convert_row_to_text(self, row: pd.Series) -> str: \n",
    "        covariates = {\n",
    "            'seqn': row['seqn'],\n",
    "            'age': row['age'],\n",
    "            'gender': row['gender'],\n",
    "            'race': row['race'],\n",
    "            'education': row['education'],\n",
    "            'marital_status': row['marital_status'],\n",
    "            'pir': row['pir']\n",
    "        }\n",
    "        time_columns = [col for col in row.index if col.startswith('time')] \n",
    "        activity_data = [row[col] for col in time_columns if pd.notna(row[col])]\n",
    "        return self.create_health_profile(covariates, activity_data)\n",
    "\n",
    "    def create_health_profile(self, covariates: Dict, activity_data: List) -> str: \n",
    "        covariates_section = self.format_covariates(covariates)\n",
    "        activity_section = self.analyze_activity(activity_data) \n",
    "\n",
    "        health_profile = f\"\"\"[Basic information]\n",
    "{covariates_section}\n",
    "\n",
    "[Physical Activity Assessment]\n",
    "{activity_section}\n",
    "\n",
    "[Health Context] \n",
    "Comprehensive health profile based on demographic characteristics and continuous physical activity monitoring using accelerometer data collected in 5-minute intervals.\n",
    "\"\"\"\n",
    "        return health_profile.strip()\n",
    " \n",
    "    def format_covariates(self, var: Dict) -> str:      \n",
    "        def safe_map(key, value):\n",
    "            if pd.isna(value) or value not in self.mappings[key]:\n",
    "                return \"unknown\"\n",
    "            return self.mappings[key][value]\n",
    "        \n",
    "        pir_text = f\"{var['pir']:.2f}\" if pd.notna(var.get('pir')) else \"unknown\"\n",
    "       \n",
    "        return f\"\"\"Age: {var.get('age', 'unknown')} years old\n",
    "Gender: {safe_map('gender', var.get('gender'))}\n",
    "Race/Ethnicity: {safe_map('race', var.get('race'))}\n",
    "Education: {safe_map('education', var.get('education'))}\n",
    "Marital Status: {safe_map('marital_status', var.get('marital_status'))}\n",
    "Poverty Income Ratio: {pir_text}\"\"\"\n",
    "        \n",
    "    def analyze_activity(self, activity_data: List) -> str:\n",
    "        if not activity_data:                \n",
    "            return \"No activity data available\"\n",
    "\n",
    "        activity_array = np.array([x for x in activity_data if pd.notna(x) and 0 <= x <= 4])\n",
    "        if len(activity_array) == 0:\n",
    "            return \"No valid activity data available\"\n",
    "\n",
    "        # activity distribution \n",
    "        activity_counts = pd.Series(activity_array).value_counts().sort_index()\n",
    "        total_intervals = len(activity_array)\n",
    "        \n",
    "        # activity level percentage \n",
    "        percentages = {}\n",
    "        for level in range(5):\n",
    "            count = activity_counts.get(level, 0)\n",
    "            percentages[level] = (count / total_intervals) * 100\n",
    "        \n",
    "        # dominant activity pattern\n",
    "        dominant_level = activity_counts.idxmax()\n",
    "        dominant_activity = self.mappings['physical_activity'][dominant_level]\n",
    "\n",
    "        # active vs sedentary time\n",
    "        active_intervals = sum(1 for x in activity_array if x >= 2)  # lifestyle, moderate, vigorous\n",
    "        active_percentage = (active_intervals / total_intervals) * 100\n",
    "\n",
    "        return f\"\"\"Monitoring Duration: {total_intervals} five-minute intervals recorded\n",
    "Activity Distribution: {percentages[0]:.1f}% sedentary, {percentages[1]:.1f}% light, {percentages[2]:.1f}% lifestyle, {percentages[3]:.1f}% moderate, {percentages[4]:.1f}% vigorous\n",
    "Primary Activity Pattern: predominantly {dominant_activity}\n",
    "Active Time: {active_percentage:.1f}% of monitored time spent in active movement\"\"\"\n",
    "\n",
    "    def batch_process(self, df: pd.DataFrame, output_file: str):\n",
    "        \"\"\"Process entire dataset\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            try:\n",
    "                text_profile = self.convert_row_to_text(row)\n",
    "                results.append({\n",
    "                    'seqn': int(row['seqn']),\n",
    "                    'text_profile': text_profile,\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {e}\")\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df['seqn'] = results_df['seqn'].astype(int)\n",
    "        \n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        return results_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a86229-b74c-40ee-bbeb-8699d9c6f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### converting data to text for \"cov_no_bmi\" ###############\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Health_data_text_converter_cov: \n",
    "\n",
    "    def __init__(self): \n",
    "        self.mappings = {\n",
    "            'gender': {1: \"male\", 2: \"female\"}, \n",
    "            'race': {1: \"Mexican American\", \n",
    "                     2: \"Other Hispanic\", \n",
    "                     3: \"Non-Hispanic White\", \n",
    "                     4: \"Non-Hispanic Black\", \n",
    "                     5: \"Other\"},\n",
    "            'education': {1: \"less than 9th grade\", \n",
    "                          2: \"9-11th grade (includes 12th grade and no diploma)\", \n",
    "                          3: \"high school graduate/GED or equivalent\", \n",
    "                          4: \"some college or associates (AA) degree\", \n",
    "                          5: \"college graduate or higher\"},\n",
    "            'marital_status': {1: \"married\", \n",
    "                        2: \"widowed\", \n",
    "                        3: \"divorced\", \n",
    "                        4: \"separated\", \n",
    "                        5: \"never married\", \n",
    "                        6: \"living with partner\"},\n",
    "            'physical_activity': {0: \"sedentary\", \n",
    "                                  1: \"light activity\",\n",
    "                                  2: \"lifestyle activity\", \n",
    "                                  3: \"moderate activity\", \n",
    "                                  4: \"vigorous activity\"}\n",
    "        }\n",
    "\n",
    "    def convert_row_to_text(self, row: pd.Series) -> str: \n",
    "        covariates = {\n",
    "            'seqn': row['seqn'],\n",
    "            'age': row['age'],\n",
    "            'gender': row['gender'],\n",
    "            'race': row['race'],\n",
    "            'education': row['education'],\n",
    "            'marital_status': row['marital_status'],\n",
    "            'pir': row['pir'],\n",
    "            'med_sbp': row['med_sbp'], \n",
    "            'med_dbp': row['med_dbp'], \n",
    "            'chol_total': row['chol_total'], \n",
    "            'chol_hdl': row['chol_hdl'], \n",
    "            'chol_ldl': row['chol_ldl'], \n",
    "            'triglyceride': row['triglyceride'], \n",
    "            'glucose': row['glucose'], \n",
    "            'crp': row['crp']\n",
    "        }\n",
    "        time_columns = [col for col in row.index if col.startswith('time')] \n",
    "        activity_data = [row[col] for col in time_columns if pd.notna(row[col])]\n",
    "        return self.create_health_profile(covariates, activity_data)\n",
    "\n",
    "    def create_health_profile(self, covariates: Dict, activity_data: List) -> str: \n",
    "        covariates_section = self.format_covariates(covariates)\n",
    "        activity_section = self.analyze_activity(activity_data) \n",
    "\n",
    "        health_profile = f\"\"\"[Basic information]\n",
    "{covariates_section}\n",
    "\n",
    "[Physical Activity Assessment]\n",
    "{activity_section}\n",
    "\n",
    "[Health Context] \n",
    "Comprehensive health profile based on demographic characteristics and continuous physical activity monitoring using accelerometer data collected in 5-minute intervals.\n",
    "\"\"\"\n",
    "        return health_profile.strip()\n",
    " \n",
    "    def format_covariates(self, var: Dict) -> str:      \n",
    "        def safe_map(key, value):\n",
    "            if pd.isna(value) or value not in self.mappings[key]:\n",
    "                return \"unknown\"\n",
    "            return self.mappings[key][value]\n",
    "        \n",
    "        pir_text = f\"{var['pir']:.2f}\" if pd.notna(var.get('pir')) else \"unknown\"\n",
    "        med_sbp_text = f\"{var['med_sbp']:.2f}\" if pd.notna(var.get('med_sbp')) else \"unknown\"\n",
    "        med_dbp_text = f\"{var['med_dbp']:.2f}\" if pd.notna(var.get('med_dbp')) else \"unknown\"\n",
    "        chol_total_text = f\"{var['chol_total']:.2f}\" if pd.notna(var.get('chol_total')) else \"unknown\"\n",
    "        chol_hdl_text = f\"{var['chol_hdl']:.2f}\" if pd.notna(var.get('chol_hdl')) else \"unknown\"\n",
    "        chol_ldl_text = f\"{var['chol_ldl']:.2f}\" if pd.notna(var.get('chol_ldl')) else \"unknown\"\n",
    "        triglyceride_text = f\"{var['triglyceride']:.2f}\" if pd.notna(var.get('triglyceride')) else \"unknown\"\n",
    "        glucose_text = f\"{var['glucose']:.2f}\" if pd.notna(var.get('glucose')) else \"unknown\"\n",
    "        crp_text = f\"{var['crp']:.2f}\" if pd.notna(var.get('crp')) else \"unknown\"\n",
    "        \n",
    "        return f\"\"\"Age: {var.get('age', 'unknown')} years old\n",
    "Gender: {safe_map('gender', var.get('gender'))}\n",
    "Race/Ethnicity: {safe_map('race', var.get('race'))}\n",
    "Education: {safe_map('education', var.get('education'))}\n",
    "Marital Status: {safe_map('marital_status', var.get('marital_status'))}\n",
    "Poverty Income Ratio: {pir_text}\n",
    "Median Systolic Blood Pressure: {med_sbp_text} mmHg\n",
    "Median Diastolic Blood Pressure: {med_dbp_text} mmHg\n",
    "Total Cholesterol: {chol_total_text} mg/dL\n",
    "HDL: {chol_hdl_text} mg/dL\n",
    "LDL: {chol_ldl_text} mg/dL\n",
    "Triglyceride: {triglyceride_text} mg/dL\n",
    "Glucose: {glucose_text} mg/dL\n",
    "C-reactive Protein: {crp_text} mg/dL\"\"\"\n",
    "\n",
    "        \n",
    "    def analyze_activity(self, activity_data: List) -> str:\n",
    "        if not activity_data:                \n",
    "            return \"No activity data available\"\n",
    "\n",
    "        activity_array = np.array([x for x in activity_data if pd.notna(x) and 0 <= x <= 4])\n",
    "        if len(activity_array) == 0:\n",
    "            return \"No valid activity data available\"\n",
    "\n",
    "        # activity distribution \n",
    "        activity_counts = pd.Series(activity_array).value_counts().sort_index()\n",
    "        total_intervals = len(activity_array)\n",
    "        \n",
    "        # activity level percentage \n",
    "        percentages = {}\n",
    "        for level in range(5):\n",
    "            count = activity_counts.get(level, 0)\n",
    "            percentages[level] = (count / total_intervals) * 100\n",
    "        \n",
    "        # dominant activity pattern\n",
    "        dominant_level = activity_counts.idxmax()\n",
    "        dominant_activity = self.mappings['physical_activity'][dominant_level]\n",
    "\n",
    "        # active vs sedentary time\n",
    "        active_intervals = sum(1 for x in activity_array if x >= 2)  # lifestyle, moderate, vigorous\n",
    "        active_percentage = (active_intervals / total_intervals) * 100\n",
    "\n",
    "        return f\"\"\"Monitoring Duration: {total_intervals} five-minute intervals recorded\n",
    "Activity Distribution: {percentages[0]:.1f}% sedentary, {percentages[1]:.1f}% light, {percentages[2]:.1f}% lifestyle, {percentages[3]:.1f}% moderate, {percentages[4]:.1f}% vigorous\n",
    "Primary Activity Pattern: predominantly {dominant_activity}\n",
    "Active Time: {active_percentage:.1f}% of monitored time spent in active movement\"\"\"\n",
    "\n",
    "\n",
    "    def batch_process(self, df: pd.DataFrame, output_file: str):\n",
    "        \"\"\"Process entire dataset\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            try:\n",
    "                text_profile = self.convert_row_to_text(row)\n",
    "                results.append({\n",
    "                    'seqn': int(row['seqn']),\n",
    "                    'text_profile': text_profile,\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {e}\")\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df['seqn'] = results_df['seqn'].astype(int)\n",
    "        \n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        return results_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddf767-fc2e-4418-a8aa-5d69d2958f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Prompt WITHOUT baseline ###############\n",
    "############################################################\n",
    "\n",
    "def create_prompt(health_profile_text):\n",
    "    prompt_template = \"\"\"Your Role: You are a well-versed scholar in the study of health outcomes, and you are able to combine various health indicators to determine a person's overweight status, defined by Body Mass Index (BMI).\n",
    "\n",
    "Background Knowledge: BMI classification uses World Health Organization guidelines where BMI greater than or equal to 25.0 kg/m^2 indicates overweight status and BMI less than 25.0 kg/m^2 indicates non overweight status. However, BMI reflects complex interactions between multiple factors and shows substantial individual variation. \n",
    "BMI varies widely within all demographic categories such as gender, race/ethnicity, education levels and marital status groups. \n",
    "Socioeconomic factors influence BMI through food access and activity opportunities. The poverty income ratio (PIR) reflects economic constraints that may affect dietary choices and physical activity access, though individuals make diverse choices within their circumstances.\n",
    "Physical activity is also a factor that affects the BMI. The physical activity data was measured with an ActiGraph AM-7164 accelerometer and it has some limitations. First, as the device only captures uniaxial movement, activities that primarily involve upper body movement may not have been recorded accurately. Second, it cannot capture water activities because it is not waterproof. Also, device compliance and wear-time varies among individuals. \n",
    "Cardiovascular and metabolic markers including systolic/diastolic blood pressure, total cholesterol, HDL, LDL, triglycerides, glucose, and C-reactive protein interact with BMI in complex ways. Some individuals maintain normal weight despite minimal recorded activity due to dietary habits, genetic metabolic differences, unmeasured activities, medical conditions, or body composition variations not captured in this dataset.\n",
    "BMI prediction requires considering multiple interacting variables while recognizing substantial individual variation that cannot be fully explained by measured factors alone.\n",
    "\n",
    "Your Task: Based on all information given, while accounting for measurement limitations and individual variations of each person in the list given, please give a prediction about each person's BMI. You need to first give your reasoning process and then give the BMI value. The format of your answer is JSON. Please do not give any additional output, and refer to the following format to give your answer:\n",
    "\n",
    "Health Profile Data: {input}\n",
    "\n",
    "```json\n",
    "{{\n",
    "“seqn”: int, \n",
    "\"inference process 1\": string, // Please give your inference process of predicting the BMI.\n",
    "\"BMI\": int,\n",
    "\"inference process 2\": string, // Please give your inference process of predicting the overweight status where 0 is non-overweight and 1 is overweight.\n",
    "\"overweight status\": int,\n",
    "}}\n",
    "```\n",
    "Based on the information above, your answer for the entire dataset is:\n",
    "\"\"\" \n",
    "    return prompt_template.format(input=health_profile_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c78171-9f75-4058-85ef-08cf8d9e37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the prompt WITHOUT BASELINE WITHOUT COV  \n",
    "\n",
    "client = openai.OpenAI(api_key='')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    converter = Health_data_text_converter()\n",
    "    df = pd.read_csv(\"003_llm_data/data_wide_no_cov_no_bmi.csv\", index_col=0)\n",
    "    llm_results = converter.batch_process(df, '003_llm_data/data_wide_no_cov_no_bmi_converted.csv')\n",
    "\n",
    "    text_df = pd.read_csv('003_llm_data/data_wide_no_cov_no_bmi_converted.csv')\n",
    "\n",
    "    checkpoint_file = '003_llm_data/llm_bmi_gpt4o_mini_checkpoint.json'\n",
    "    results = []\n",
    "    \n",
    "    # Load existing progress if available\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        processed_count = len(results)\n",
    "        remaining_df = text_df.iloc[processed_count:].reset_index(drop=True)\n",
    "        print(f\"Resuming from row {processed_count}\")\n",
    "    else:\n",
    "        results = []\n",
    "        remaining_df = text_df\n",
    "        processed_count = 0\n",
    "    \n",
    "    # Process remaining data\n",
    "    for index, row in tqdm(remaining_df.iterrows(), total=len(remaining_df), initial=processed_count):\n",
    "        health_profile = row['text_profile']\n",
    "        original_seqn = row['seqn']\n",
    "        full_prompt = create_prompt(health_profile)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "                temperature=0.3,\n",
    "                max_tokens=4096\n",
    "            )\n",
    "            \n",
    "            # Get response text\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # Extract JSON from ```json blocks\n",
    "            json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "                prediction_data = json.loads(json_str)\n",
    "                prediction_data['seqn'] = original_seqn\n",
    "                results.append(prediction_data)\n",
    "            else:\n",
    "                # Fallback: try to find any JSON-like structure\n",
    "                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "                if json_match:\n",
    "                    json_str = json_match.group(0)\n",
    "                    prediction_data = json.loads(json_str)\n",
    "                    prediction_data['seqn'] = original_seqn\n",
    "                    results.append(prediction_data)\n",
    "                else:\n",
    "                    print(f\"No JSON found in response for row {index}\")\n",
    "                    results.append(None)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            results.append(None)\n",
    "        \n",
    "        # Save checkpoint every 10 rows\n",
    "        if len(results) % 10 == 0:\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Final save\n",
    "    os.makedirs('003_llm_data', exist_ok=True)\n",
    "    with open('003_llm_data/llm_bmi_gpt4o_mini.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Clean up checkpoint file\n",
    "    if os.path.exists(checkpoint_file):1\n",
    "    os.remove(checkpoint_file)\n",
    "    \n",
    "    print(f\"Saved {len([r for r in results if r is not None])} successful predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f38da-814b-49c5-8391-eebb31d6aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the prompt WITHOUT BASELINE WITH COV  \n",
    "\n",
    "client = openai.OpenAI(api_key='')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    converter = Health_data_text_converter_cov()\n",
    "    df = pd.read_csv(\"003_llm_data/data_wide_cov_no_bmi.csv\", index_col=0)\n",
    "    llm_results = converter.batch_process(df, '003_llm_data/data_wide_cov_no_bmi_converted.csv')\n",
    "\n",
    "    text_df = pd.read_csv('003_llm_data/data_wide_cov_no_bmi_converted.csv')\n",
    "\n",
    "    checkpoint_file = '003_llm_data/llm_bmi_gpt4o_mini_cov_checkpoint.json'\n",
    "    results = []\n",
    "    \n",
    "    # Load existing progress if available\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        processed_count = len(results)\n",
    "        remaining_df = text_df.iloc[processed_count:].reset_index(drop=True)\n",
    "        print(f\"Resuming from row {processed_count}\")\n",
    "    else:\n",
    "        results = []\n",
    "        remaining_df = text_df\n",
    "        processed_count = 0\n",
    "    \n",
    "    # Process remaining data\n",
    "    for index, row in tqdm(remaining_df.iterrows(), total=len(remaining_df), initial=processed_count):\n",
    "        health_profile = row['text_profile']\n",
    "        original_seqn = row['seqn']\n",
    "        full_prompt = create_prompt(health_profile)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "                temperature=0.3,\n",
    "                max_tokens=4096\n",
    "            )\n",
    "            \n",
    "            # Get response text\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # Extract JSON from ```json blocks\n",
    "            json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "                prediction_data = json.loads(json_str)\n",
    "                prediction_data['seqn'] = original_seqn\n",
    "                results.append(prediction_data)\n",
    "            else:\n",
    "                # Fallback: try to find any JSON-like structure\n",
    "                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "                if json_match:\n",
    "                    json_str = json_match.group(0)\n",
    "                    prediction_data = json.loads(json_str)\n",
    "                    prediction_data['seqn'] = original_seqn\n",
    "                    results.append(prediction_data)\n",
    "                else:\n",
    "                    print(f\"No JSON found in response for row {index}\")\n",
    "                    results.append(None)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            results.append(None)\n",
    "        \n",
    "        # Save checkpoint every 10 rows\n",
    "        if len(results) % 10 == 0:\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Final save\n",
    "    os.makedirs('003_llm_data', exist_ok=True)\n",
    "    with open('003_llm_data/llm_bmi_gpt4o_mini_cov.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # Clean up checkpoint file\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        os.remove(checkpoint_file)\n",
    "    \n",
    "    print(f\"Saved {len([r for r in results if r is not None])} successful predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503864b-5227-439c-9492-f13287a2992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d586952-218d-4707-8890-ca14ff4de99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
