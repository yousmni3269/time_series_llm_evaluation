{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9236665-5642-4478-8b6a-415250a22c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install momentfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9536921-c901-4d79-9992-8217bf745ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the MOMENT model \n",
    "\n",
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\", \n",
    "    model_kwargs={'task_name': 'embedding'}, # We are loading the model in `embedding` mode to learn representations\n",
    "    local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    ")\n",
    "\n",
    "model.init()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323f89c-9e69-462c-8bcc-5f8fcf4852cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parameters in the encoder\n",
    "num_params = sum(p.numel() for p in model.encoder.parameters())\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6dead-0532-480b-b8b9-f1da0a4fd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240327ce-1f32-481b-a6b0-856184f4a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data \n",
    "\n",
    "df_min5 = pd.read_csv(\"002_data/data_wide.csv\", index_col=0)                        # aggregated 5min \n",
    "df_min1 = pd.read_csv(\"002_data/data_raw_full.csv\", index_col=0)                    # raw 1min \n",
    "\n",
    "df_min20 = pd.read_csv(\"002_data/data_wide_min20.csv\", index_col=0)                 # aggregated 20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b6e96-0bb7-4dbe-81db-53f060e8ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data into chunks to fit into MOMENT input (max 512 tokens) \n",
    "\n",
    "def prepare_chunks(df, value_columns, n_channels=1, max_len=512):\n",
    "    data = df[value_columns].values\n",
    "    n_batch, n_context = data.shape\n",
    "\n",
    "    # context per channel\n",
    "    context_per_channel = n_context // n_channels\n",
    "    if n_context % n_channels != 0:\n",
    "        raise ValueError(\"n_context must be divisible by n_channels\")\n",
    "\n",
    "    # number of full 512 windows\n",
    "    n_full_chunks = context_per_channel // max_len\n",
    "    chunks = []\n",
    "    \n",
    "    for chunk_idx in range(n_full_chunks):\n",
    "        start = chunk_idx * max_len\n",
    "        end = start + max_len\n",
    "        chunk_raw = data[:, start:end]  # (batch, 512)\n",
    "        chunk_reshaped = chunk_raw.reshape(n_batch, n_channels, max_len)\n",
    "        chunks.append(torch.FloatTensor(chunk_reshaped))\n",
    "\n",
    "    remainder = context_per_channel % max_len\n",
    "    if remainder > 0:\n",
    "        start = n_full_chunks * max_len\n",
    "        end = context_per_channel\n",
    "        chunk_raw = data[:, start:end]  # (batch, remainder)\n",
    "        chunk_reshaped = chunk_raw.reshape(n_batch, n_channels, remainder)\n",
    "        chunks.append(torch.FloatTensor(chunk_reshaped))\n",
    "        print(f\"Added partial chunk {n_full_chunks} with length {remainder}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cd900-5ea9-4053-8cdb-2a52ad84bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## For 5 min aggregated data ########################\n",
    "########################################################################\n",
    "\n",
    "model.init()\n",
    "\n",
    "val_col_min5 = [col for col in df_min5.columns if col.startswith('time')]\n",
    "\n",
    "df_min5_tensor = prepare_chunks(df_min5, val_col_min5, n_channels=1)\n",
    "df_min5_c0 = df_min5_tensor[0]  # first 512 inputs \n",
    "\n",
    "# get embeddings in two subsets due to time/ efficiency \n",
    "\n",
    "df_min5_s1 = df_min5_c0[:3500]\n",
    "df_min5_s2 = df_min5_c0[3500:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_df_min5_s1 = model(x_enc=df_min5_s1)\n",
    "    output_df_min5_s2 = model(x_enc=df_min5_s2)\n",
    "\n",
    "min5_embeddings_s1 = output_df_min5_s1.embeddings \n",
    "min5_embeddings_s2 = output_df_min5_s2.embeddings \n",
    "\n",
    "min5_embeddings = torch.cat([min5_embeddings_s1, min5_embeddings_s2], dim=0)\n",
    "min5_embeddings_np = min5_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# combine with demographic columns \n",
    "demo_cols = ['seqn', 'gender', 'age', 'race', 'education', 'marital_status', 'pir', 'bmi']\n",
    "min5_data_all = df_min5.reset_index(drop=True)\n",
    "min5_embeddings_df = pd.concat([min5_data_all[demo_cols], pd.DataFrame(min5_embeddings_np)], axis=1)\n",
    "\n",
    "min5_original_cols = demo_cols\n",
    "min5_embedding_cols = list(range(min5_embeddings_np.shape[1]))\n",
    "min5_embeddings_df.columns = min5_original_cols + min5_embedding_cols\n",
    "min5_embeddings_df.index = range(1, len(min5_embeddings_df) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b11be7-69ba-4d46-95ba-ed8fdd6c6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "min5_embeddings_df.to_csv(\"./002_data/embeddings_min5_moment1024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d52185-2e71-4852-80ab-e6e72081ae3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3c948-f488-4d9a-a760-4219e474da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## For 1 min raw data ########################\n",
    "########################################################################\n",
    "\n",
    "model.init()\n",
    "\n",
    "val_col_min1 = [col for col in df_min1.columns if col.startswith('x')]\n",
    "\n",
    "df_min1_tensor = prepare_chunks(df_min1, val_col_min1, n_channels=1)\n",
    "df_min1_c0 = df_min1_tensor[0]  # first 512 inputs \n",
    "\n",
    "# get embeddings in two subsets due to time/ efficiency \n",
    "\n",
    "df_min1_s1 = df_min1_tensor[:3500]\n",
    "df_min1_s2 = df_min1_tensor[3500:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_df_min1_s1 = model(x_enc=df_min1_s1)\n",
    "    output_df_min1_s2 = model(x_enc=df_min1_s2)\n",
    "\n",
    "min1_embeddings_s1 = output_df_min1_s1.embeddings \n",
    "min1_embeddings_s2 = output_df_min1_s2.embeddings \n",
    "min1_embeddings = torch.cat([min1_embeddings_s1, min1_embeddings_s2], dim=0)\n",
    "min1_embeddings_np = min5_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# combine with demographic columns \n",
    "demo_cols = ['seqn', 'gender', 'age', 'race', 'education', 'marital_status', 'pir', 'bmi']\n",
    "min1_data_all = df_min1.reset_index(drop=True)\n",
    "min1_embeddings_df = pd.concat([min1_data_all[demo_cols], pd.DataFrame(min1_embeddings_np)], axis=1)\n",
    "\n",
    "min1_original_cols = demo_cols\n",
    "min1_embedding_cols = list(range(min1_embeddings_np.shape[1]))\n",
    "min1_embeddings_df.columns = min1_original_cols + min1_embedding_cols\n",
    "min1_embeddings_df.index = range(1, len(min1_embeddings_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b16265-6d4a-431f-aff6-574806bf1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "min1_embeddings_df.to_csv(\"./002_data/embeddings_min1_moment1024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb7558-e69f-4268-a1fe-6c9d828c2295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ea103-5e90-45f9-8750-3181ed998a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## For 20 min aggregated data ########################\n",
    "########################################################################\n",
    "\n",
    "model.init()\n",
    "\n",
    "val_col_min20 = [col for col in df_min20.columns if col.startswith('time')]\n",
    "\n",
    "df_min20_tensor = prepare_chunks(df_min20, val_col_min20, n_channels=1)\n",
    "df_min20_c0 = df_min20_tensor[0]  # first 512 inputs \n",
    "\n",
    "# get embeddings in two subsets due to time/ efficiency \n",
    "\n",
    "df_min20_s1 = df_min20_c0[:3500]\n",
    "df_min20_s2 = df_min20_c0[3500:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_df_min20_s1 = model(x_enc=df_min20_s1)\n",
    "    output_df_min20_s2 = model(x_enc=df_min20_s2)\n",
    "\n",
    "min20_embeddings_s1 = output_df_min20_s1.embeddings \n",
    "min20_embeddings_s2 = output_df_min20_s2.embeddings \n",
    "\n",
    "min20_embeddings = torch.cat([min20_embeddings_s1, min20_embeddings_s2], dim=0)\n",
    "min20_embeddings_np = min20_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# combine with demographic columns \n",
    "demo_cols = ['seqn', 'gender', 'age', 'race', 'education', 'marital_status', 'pir', 'bmi']\n",
    "min20_data_all = df_min20.reset_index(drop=True)\n",
    "min20_embeddings_df = pd.concat([min20_data_all[demo_cols], pd.DataFrame(min20_embeddings_np)], axis=1)\n",
    "\n",
    "min20_original_cols = demo_cols\n",
    "min20_embedding_cols = list(range(min20_embeddings_np.shape[1]))\n",
    "min20_embeddings_df.columns = min20_original_cols + min20_embedding_cols\n",
    "min20_embeddings_df.index = range(1, len(min20_embeddings_df) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee9a05-3aa6-450f-a4e9-83c637206f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "min20_embeddings_df.to_csv(\"./002_data/embeddings_min20_moment1024.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
